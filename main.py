import os
import requests
from bs4 import BeautifulSoup

BASE_DIR = os.getcwd()

def crawl():
    try:
        url = input("Please Enter The URL : https://www.")
        os.chdir('quotet')
        os.system("del tokens.txt")
        with open("url.txt", "w") as f:
            f.write(url)
            f.close()
        os.chdir(BASE_DIR)
        os.system(f"cd quotet && scrapy crawl GetCSRFtoken")
        os.system(f"cd quotet && scrapy crawl GetCSRFtoken")
    except:
        pass

def checkVulnerable():
    try:
        os.chdir('quotet')
        with open("tokens.txt", "r") as f:
            tokens = f.readlines()
            f.close()
            if((tokens[0][:-1])==tokens[1]):
                print(">>-----------------CSRF Vulnerable------------------<<")
            else:
                print(">>-----------------NOT CSRF Vulnerable------------------<<")
    except:
        pass

def checkMissingTokens():
    try:
        os.chdir('quotet')
        with open("url.txt", "r") as f:
            url = f.read()
            f.close()
        os.chdir(BASE_DIR)
        response = requests.get(f"https://{url}")
        soup = BeautifulSoup(response.content, 'html.parser')
        forms = soup.find_all('form')
        for form in forms:
            if not form.find('input', {'name': 'csrf_token'}):
                print(f">>-----------------Missing CSRF Token in Form: {form}------------------<<")
        headers = response.headers
        if 'X-CSRF-Token' not in headers:
            print(">>-----------------Missing CSRF Token in Headers------------------<<")
    except:
        pass

crawl()
checkVulnerable()
checkMissingTokens()
